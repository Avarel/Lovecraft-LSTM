{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lovecraft-lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzonebbJlVk6",
        "colab_type": "code",
        "outputId": "442d8697-4f64-48d6-8b3e-5d43867422c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Collecting tensorflow-gpu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/44/47f0722aea081697143fbcf5d2aa60d1aee4aaacb5869aee2b568974777b/tensorflow_gpu-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (380.8MB)\n",
            "\u001b[K     |████████████████████████████████| 380.8MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (3.11.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (0.9.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (0.8.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.13.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.17.4)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 33.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (0.33.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (0.1.8)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.25.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (1.11.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /tensorflow-2.1.0/python3.6 (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /tensorflow-2.1.0/python3.6 (from protobuf>=3.6.1->tensorflow-gpu) (42.0.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.16.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.22.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /tensorflow-2.1.0/python3.6 (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.9.0)\n",
            "Requirement already satisfied: h5py in /tensorflow-2.1.0/python3.6 (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /tensorflow-2.1.0/python3.6 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (1.25.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.2.7)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /tensorflow-2.1.0/python3.6 (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /tensorflow-2.1.0/python3.6 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /tensorflow-2.1.0/python3.6 (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu) (0.4.8)\n",
            "\u001b[31mERROR: tensorflow 2.1.0rc1 has requirement tensorboard<2.2.0,>=2.1.0, but you'll have tensorboard 2.0.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.1.0rc1 has requirement tensorflow-estimator<2.2.0,>=2.1.0rc0, but you'll have tensorflow-estimator 2.0.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow-gpu\n",
            "  Found existing installation: tensorflow-estimator 2.1.0\n",
            "    Uninstalling tensorflow-estimator-2.1.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.1.0\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "Successfully installed tensorboard-2.0.2 tensorflow-estimator-2.0.1 tensorflow-gpu-2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCW7XaUsl4um",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2f0cd72-db1b-4c44-9161-38db5b38900e"
      },
      "source": [
        "!unzip -o \"./Archive.zip\" -d \"./\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  ./Archive.zip\n",
            "   creating: ./data/\n",
            "  inflating: ./data/.DS_Store        \n",
            "  inflating: ./__MACOSX/data/._.DS_Store  \n",
            "   creating: ./data/training/\n",
            "   creating: ./data/validation/\n",
            "  inflating: ./data/training/dunwich_8.txt  \n",
            "  inflating: ./data/training/mountain_11.txt  \n",
            "  inflating: ./data/training/mountain_10.txt  \n",
            "  inflating: ./data/training/shadow_inns_1.txt  \n",
            "  inflating: ./data/training/dunwich_9.txt  \n",
            "  inflating: ./data/training/dagon.txt  \n",
            "  inflating: ./data/training/shadow_inns_3.txt  \n",
            "  inflating: ./data/training/mountain_12.txt  \n",
            "  inflating: ./data/training/shadow_inns_2.txt  \n",
            "  inflating: ./data/training/.DS_Store  \n",
            "  inflating: ./__MACOSX/data/training/._.DS_Store  \n",
            "  inflating: ./data/training/colour.txt  \n",
            "  inflating: ./data/training/shadow_inns_5.txt  \n",
            "  inflating: ./data/training/shadow_inns_4.txt  \n",
            "  inflating: ./data/training/mountain_2.txt  \n",
            "  inflating: ./data/training/mountain_3.txt  \n",
            "  inflating: ./data/training/mountain_1.txt  \n",
            "  inflating: ./data/training/mountain_4.txt  \n",
            "  inflating: ./data/training/mountain_5.txt  \n",
            "  inflating: ./data/training/mountain_7.txt  \n",
            "  inflating: ./data/training/mountain_6.txt  \n",
            "  inflating: ./data/training/mountain_8.txt  \n",
            "  inflating: ./data/training/mountain_9.txt  \n",
            "  inflating: ./data/training/fear_4.txt  \n",
            "  inflating: ./data/training/the_outsider.txt  \n",
            "  inflating: ./data/training/fear_1.txt  \n",
            "  inflating: ./data/training/fear_3.txt  \n",
            "  inflating: ./data/training/fear_2.txt  \n",
            "  inflating: ./data/training/dunwich_1.txt  \n",
            "  inflating: ./data/training/dunwich_2.txt  \n",
            "  inflating: ./data/training/dunwich_3.txt  \n",
            "  inflating: ./data/training/dunwich_7.txt  \n",
            "  inflating: ./data/training/dunwich_10.txt  \n",
            "  inflating: ./data/training/dream_witch.txt  \n",
            "  inflating: ./data/training/dunwich_6.txt  \n",
            "  inflating: ./data/training/dunwich_4.txt  \n",
            "  inflating: ./data/training/dunwich_5.txt  \n",
            "  inflating: ./data/validation/call_of_cthulhu_3.txt  \n",
            "  inflating: ./data/validation/call_of_cthulhu_2.txt  \n",
            "  inflating: ./data/validation/call_of_cthulhu_1.txt  \n",
            "  inflating: ./data/validation/.DS_Store  \n",
            "  inflating: ./__MACOSX/data/validation/._.DS_Store  \n",
            "  inflating: ./data/validation/shadowtime_1.txt  \n",
            "  inflating: ./data/validation/whisperer_5.txt  \n",
            "  inflating: ./data/validation/whisperer_4.txt  \n",
            "  inflating: ./data/validation/shadowtime_2.txt  \n",
            "  inflating: ./data/validation/whisperer_6.txt  \n",
            "  inflating: ./data/validation/whisperer_7.txt  \n",
            "  inflating: ./data/validation/shadowtime_3.txt  \n",
            "  inflating: ./data/validation/shadowtime_7.txt  \n",
            "  inflating: ./data/validation/whisperer_3.txt  \n",
            "  inflating: ./data/validation/whisperer_2.txt  \n",
            "  inflating: ./data/validation/shadowtime_6.txt  \n",
            "  inflating: ./data/validation/shadowtime_4.txt  \n",
            "  inflating: ./data/validation/whisperer_1.txt  \n",
            "  inflating: ./data/validation/shadowtime_5.txt  \n",
            "  inflating: ./data/validation/shadowtime_8.txt  \n",
            "  inflating: ./data/validation/whisperer_8.txt  \n",
            "  inflating: ./data.py               \n",
            "  inflating: ./main.py               \n",
            "  inflating: ./ml.py                 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jf39C0yTmHak",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6ad45bec-78f9-47a0-fcd0-ed9d0f21ea64"
      },
      "source": [
        "import ml\n",
        "import data\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Persistent variables that I have not yet compartmentalize.\n",
        "batch_size: int = 64\n",
        "embedding_dim: int = 256\n",
        "rnn_units: int = 1024\n",
        "checkpoint_dir = os.path.join(\".\", \"checkpoints\", 'cp_x')\n",
        "\n",
        "vocab_len, char2int, int2char, tr_dataset, val_dataset = ml.get_datasets(batch_size)\n",
        "\n",
        "# Train and build the model.\n",
        "model = ml.build_model(\n",
        "    vocab_len,\n",
        "    embedding_dim,\n",
        "    rnn_units,\n",
        "    batch_size\n",
        ")\n",
        "model.summary()\n",
        "\n",
        "ml.train_model(model, tr_dataset, val_dataset, checkpoint_dir)\n",
        "\n",
        "# Reconstruct and feed the checkpoint data into the model.\n",
        "model = ml.build_model(vocab_len, embedding_dim, rnn_units, 1)\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "\n",
        "print(ml.generate_text(model, char2int, int2char, \"the deep dark\"))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:ml:Looking through data...\n",
            "INFO:ml:Looking through training data...\n",
            "DEBUG:data:Found file the_outsider.txt\n",
            "DEBUG:data:Found file dream_witch.txt\n",
            "DEBUG:data:Found file mountain_1.txt\n",
            "DEBUG:data:Found file shadow_inns_1.txt\n",
            "DEBUG:data:Found file dunwich_6.txt\n",
            "DEBUG:data:Found file fear_4.txt\n",
            "DEBUG:data:Found file dunwich_9.txt\n",
            "DEBUG:data:Found file mountain_6.txt\n",
            "DEBUG:data:Found file dagon.txt\n",
            "DEBUG:data:Found file mountain_9.txt\n",
            "DEBUG:data:Found file dunwich_5.txt\n",
            "DEBUG:data:Found file dunwich_4.txt\n",
            "DEBUG:data:Found file fear_3.txt\n",
            "DEBUG:data:Found file dunwich_3.txt\n",
            "DEBUG:data:Found file mountain_12.txt\n",
            "DEBUG:data:Found file mountain_3.txt\n",
            "DEBUG:data:Found file shadow_inns_3.txt\n",
            "DEBUG:data:Found file mountain_10.txt\n",
            "DEBUG:data:Found file mountain_11.txt\n",
            "DEBUG:data:Found file fear_2.txt\n",
            "DEBUG:data:Found file shadow_inns_2.txt\n",
            "DEBUG:data:Found file mountain_4.txt\n",
            "DEBUG:data:Found file mountain_5.txt\n",
            "DEBUG:data:Found file colour.txt\n",
            "DEBUG:data:Found file shadow_inns_4.txt\n",
            "DEBUG:data:Found file fear_1.txt\n",
            "DEBUG:data:Found file dunwich_10.txt\n",
            "DEBUG:data:Found file shadow_inns_5.txt\n",
            "DEBUG:data:Found file dunwich_7.txt\n",
            "DEBUG:data:Found file mountain_8.txt\n",
            "DEBUG:data:Found file dunwich_2.txt\n",
            "DEBUG:data:Found file dunwich_8.txt\n",
            "DEBUG:data:Found file mountain_7.txt\n",
            "DEBUG:data:Found file dunwich_1.txt\n",
            "DEBUG:data:Found file mountain_2.txt\n",
            "INFO:ml:Found 35 training files.\n",
            "INFO:ml:Looking through validation data...\n",
            "DEBUG:data:Found file whisperer_3.txt\n",
            "DEBUG:data:Found file call_of_cthulhu_2.txt\n",
            "DEBUG:data:Found file call_of_cthulhu_1.txt\n",
            "DEBUG:data:Found file shadowtime_1.txt\n",
            "DEBUG:data:Found file shadowtime_5.txt\n",
            "DEBUG:data:Found file whisperer_8.txt\n",
            "DEBUG:data:Found file whisperer_1.txt\n",
            "DEBUG:data:Found file shadowtime_6.txt\n",
            "DEBUG:data:Found file call_of_cthulhu_3.txt\n",
            "DEBUG:data:Found file shadowtime_7.txt\n",
            "DEBUG:data:Found file whisperer_6.txt\n",
            "DEBUG:data:Found file whisperer_4.txt\n",
            "DEBUG:data:Found file shadowtime_2.txt\n",
            "DEBUG:data:Found file shadowtime_3.txt\n",
            "DEBUG:data:Found file shadowtime_4.txt\n",
            "DEBUG:data:Found file shadowtime_8.txt\n",
            "DEBUG:data:Found file whisperer_7.txt\n",
            "DEBUG:data:Found file whisperer_2.txt\n",
            "DEBUG:data:Found file whisperer_5.txt\n",
            "INFO:ml:Found 19 validation files.\n",
            "INFO:ml:Preparing data...\n",
            "INFO:ml:Training text size:       \t708676\n",
            "INFO:ml:Validation text size:     \t369735\n",
            "INFO:ml:Training:validation ratio:\t1.916713\n",
            "INFO:ml:Building model...\n",
            "INFO:ml:Begin training... (this will take a while)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (64, None, 256)           24064     \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (64, None, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (64, None, 1024)          5246976   \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "lstm_5 (LSTM)                (64, None, 1024)          8392704   \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (64, None, 1024)          0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (64, None, 94)            96350     \n",
            "=================================================================\n",
            "Total params: 13,760,094\n",
            "Trainable params: 13,760,094\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train for 55 steps, validate for 28 steps\n",
            "Epoch 1/100\n",
            "55/55 [==============================] - 58s 1s/step - loss: 3.1120 - val_loss: 2.8631\n",
            "Epoch 2/100\n",
            "55/55 [==============================] - 50s 912ms/step - loss: 2.6493 - val_loss: 2.4413\n",
            "Epoch 3/100\n",
            "55/55 [==============================] - 50s 912ms/step - loss: 2.3028 - val_loss: 2.2026\n",
            "Epoch 4/100\n",
            "55/55 [==============================] - 50s 908ms/step - loss: 2.0975 - val_loss: 2.0164\n",
            "Epoch 5/100\n",
            "55/55 [==============================] - 50s 909ms/step - loss: 1.9292 - val_loss: 1.8622\n",
            "Epoch 6/100\n",
            "55/55 [==============================] - 50s 915ms/step - loss: 1.7895 - val_loss: 1.7492\n",
            "Epoch 7/100\n",
            "55/55 [==============================] - 51s 919ms/step - loss: 1.6720 - val_loss: 1.6483\n",
            "Epoch 8/100\n",
            "55/55 [==============================] - 50s 915ms/step - loss: 1.5744 - val_loss: 1.5729\n",
            "Epoch 9/100\n",
            "55/55 [==============================] - 50s 915ms/step - loss: 1.4960 - val_loss: 1.5155\n",
            "Epoch 10/100\n",
            "55/55 [==============================] - 50s 914ms/step - loss: 1.4341 - val_loss: 1.4783\n",
            "Epoch 11/100\n",
            "55/55 [==============================] - 50s 912ms/step - loss: 1.3824 - val_loss: 1.4496\n",
            "Epoch 12/100\n",
            "55/55 [==============================] - 50s 912ms/step - loss: 1.3376 - val_loss: 1.4291\n",
            "Epoch 13/100\n",
            "40/55 [====================>.........] - ETA: 11s - loss: 1.2989"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asj3kwGmpNPz",
        "colab_type": "code",
        "outputId": "8f7829e3-67d1-47c3-c94f-a643fc238ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "!cd ./checkpoints; ls; cd checkpoint_01.02.20-21.56.40; ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint_01.02.20-21.56.40\n",
            "checkpoint\t\t     ckpt_22.data-00000-of-00002\n",
            "ckpt_10.data-00000-of-00002  ckpt_22.data-00001-of-00002\n",
            "ckpt_10.data-00001-of-00002  ckpt_22.index\n",
            "ckpt_10.index\t\t     ckpt_23.data-00000-of-00002\n",
            "ckpt_11.data-00000-of-00002  ckpt_23.data-00001-of-00002\n",
            "ckpt_11.data-00001-of-00002  ckpt_23.index\n",
            "ckpt_11.index\t\t     ckpt_24.data-00000-of-00002\n",
            "ckpt_12.data-00000-of-00002  ckpt_24.data-00001-of-00002\n",
            "ckpt_12.data-00001-of-00002  ckpt_24.index\n",
            "ckpt_12.index\t\t     ckpt_25.data-00000-of-00002\n",
            "ckpt_13.data-00000-of-00002  ckpt_25.data-00001-of-00002\n",
            "ckpt_13.data-00001-of-00002  ckpt_25.index\n",
            "ckpt_13.index\t\t     ckpt_26.data-00000-of-00002\n",
            "ckpt_14.data-00000-of-00002  ckpt_26.data-00001-of-00002\n",
            "ckpt_14.data-00001-of-00002  ckpt_26.index\n",
            "ckpt_14.index\t\t     ckpt_2.data-00000-of-00002\n",
            "ckpt_15.data-00000-of-00002  ckpt_2.data-00001-of-00002\n",
            "ckpt_15.data-00001-of-00002  ckpt_2.index\n",
            "ckpt_15.index\t\t     ckpt_3.data-00000-of-00002\n",
            "ckpt_16.data-00000-of-00002  ckpt_3.data-00001-of-00002\n",
            "ckpt_16.data-00001-of-00002  ckpt_3.index\n",
            "ckpt_16.index\t\t     ckpt_4.data-00000-of-00002\n",
            "ckpt_17.data-00000-of-00002  ckpt_4.data-00001-of-00002\n",
            "ckpt_17.data-00001-of-00002  ckpt_4.index\n",
            "ckpt_17.index\t\t     ckpt_5.data-00000-of-00002\n",
            "ckpt_18.data-00000-of-00002  ckpt_5.data-00001-of-00002\n",
            "ckpt_18.data-00001-of-00002  ckpt_5.index\n",
            "ckpt_18.index\t\t     ckpt_6.data-00000-of-00002\n",
            "ckpt_19.data-00000-of-00002  ckpt_6.data-00001-of-00002\n",
            "ckpt_19.data-00001-of-00002  ckpt_6.index\n",
            "ckpt_19.index\t\t     ckpt_7.data-00000-of-00002\n",
            "ckpt_1.data-00000-of-00002   ckpt_7.data-00001-of-00002\n",
            "ckpt_1.data-00001-of-00002   ckpt_7.index\n",
            "ckpt_1.index\t\t     ckpt_8.data-00000-of-00002\n",
            "ckpt_20.data-00000-of-00002  ckpt_8.data-00001-of-00002\n",
            "ckpt_20.data-00001-of-00002  ckpt_8.index\n",
            "ckpt_20.index\t\t     ckpt_9.data-00000-of-00002\n",
            "ckpt_21.data-00000-of-00002  ckpt_9.data-00001-of-00002\n",
            "ckpt_21.data-00001-of-00002  ckpt_9.index\n",
            "ckpt_21.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rPi_zQ7p1vR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('./checkpoints/checkpoint_01.02.20-21.56.40/ckpt_26.data-00000-of-00002') "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}